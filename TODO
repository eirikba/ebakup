Handle files that change during backup

---------------------------------------------------------------------------

Other performance ideas?

Maybe using multiple threads to read data? This would eliminate the
wait between read commands and could also provide the scheduler with
more options to read more efficiently. (When backing up lots of small
files that already have duplicates in the content store, it seems
there are read() calls that are by far the most expensive ones,
leaving the program running almost entirely in iowait.) A quick test
application that only reads files without doing anything else seems to
have around 2x speedup with this trick (when using around 10 threads).

Try to read files in disk allocation order. Don't know how to figure
that out, but sorting on inode order could be a good approximation.
Same test application as above gave more than 10 times speedup with
this trick (well, sorting on name in this case).


---------------------------------------------------------------------------

Handle failed backups

If a backup does not complete correctly, there will/may be some cruft
left behind. Particularly after other improvements (such as "buffer
database changes").

- Temporary files that haven't been deleted.
  - Temporary add-to-content-store file
  - Backup database ".new" file
  - Half-done shadow tree
- Files in the content store that aren't listed in the content db
- Shadow trees that are missing their backup database

---------------------------------------------------------------------------

Avoid writing "small" duplicate files to disk needlessly

Currently the code writes every file to a temporary file before
checking whether the file already exists. I should have a moderately
large buffer (100MiB?) and any file smaller than that should just be
read into that buffer so I can check whether it already exists in the
content store before writing.

Actually, reading twice may be better than writing during the first
read, as the second read is likely to be filled from the OS's disk
cache.

---------------------------------------------------------------------------

Buffer database changes

Instead of writing every change to the database as they are made, I
could buffer up a bunch of changes and write them together. Probably
the best solution here would be to have some in-memory storage of the
data not yet written, and then have a background thread that wakes up
every 5 minutes and writes any buffered data to disk.

---------------------------------------------------------------------------

Handle special files

Symlinks are currently ignored. That's probably not optimal. Maybe
symlinks pointing out of tree should be ignored, while symlinks to
in-tree files (and directories) should be registered as symlinks (with
path)? Or may symlinks out-of-tree should be registered too, but
obviously not in the shadow tree?

Similar for sockets and pipes. Register in database, but don't add to
shadow tree?

What about device files? Should not occur, but could be registered in
the database none the less.

---------------------------------------------------------------------------

BackupCollection._make_path_from_content_id() hardcodes the splitting points.

Test: Not created

Each path component (except the last) should have the same length as
all other items in the same directory.


---------------------------------------------------------------------------

Many "problematic" cases not handled

There are plenty of cases that aren't fully handled. In particular
cases that shouldn't happen when everything is correct. Most of these
can be found by searching for NotTestedError.

---------------------------------------------------------------------------
